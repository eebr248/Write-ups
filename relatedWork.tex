\chapter{Related Work}
The space around us can be categorized into three main regions: personal space (near field), action space (medium field), and vista space (far field) \cite{c95}. In general, personal space is the area within a typical user's arm reach, action space is beyond personal space up to roughly 30m, and vista space is considered all further distances. Previous research in action space has shown that distances can be quite accurately estimated in the \textit{Real World} (RW) at up to 20m, while these are mostly underestimated in \textit{Virtual Environments} (VEs) \cite{lk03,WK98,RW05,TWG+04}. Similarly, distance estimation is distorted but overestimated in personal space (or near field) in VEs as compared to the real world \cite{EAH+14,RBG+95} which may have implications on physical reaching behavior of participants in the near field. Willemsen et al. \cite{WCC+09} illustrated that the mechanical properties of the HMD can potentially contribute to distance underestimation as measured using blind walking%(but not using timed imagined walking)
. However, Grechkin et al. \cite{GNP+10} pointed out that mechanical properties of the HMD cannot be the only reason for the distance underestimation in VE. Grechkin et al. \cite{GNP+10} compared RW viewing, both with and without an HMD, to four VR presentations; i) virtual world in HMD, ii) \textit{Augmented Reality} (AR) in HMD, iii) virtual world in \textit{Large Screen Immersive Display} (LSID) and iv) photorealistic virtual world in LSID. They also found that underestimation occurred in all VE conditions, although the magnitude of the errors varied substantially. In another study, Witmer and Kline \cite{WK98} demonstrated that users underestimated distances in both the RW and a VE with underestimation in VE being more pronounced. They also pointed out that traversing distances in VE reduced the overall underestimation which could be due to the fact of taking an action in VE.

Ongoing perception is an inherent component of the normal action-perception cycle. Actions influences perception which then effects how we interact with the world or change our view of it \cite{wv05}. Generally, action impacts the way we perceive the third-dimension or depth perception. Some previous work studied the effect of the potential effort required to complete a task and its effect on perceiving the environment. Proffitt et al. \cite{ps+03} showed that wearing a heavy backpack caused distance overestimation. In another study Willemsen et al. \cite{WCC+09} found distance underestimation that could partially be explained by the weight and forces from the HMD during the walking task. Also, the perceived distance is affected by action capabilities of the body \cite{lw+09}. For instance, Linkenauger et al. \cite{lw+09} showed that the tool orientation and its easiness to grasp had influenced the perceived closeness and reachability of the tool. The removal of perceptual feedback is a perturbation that adversely effects the performance of actions \cite{BP98}.

The action-perception cycle also has an effect on overcoming the perturbations of visual distance and direction through continuous calibration \cite{BR99,BC12,ZBC+13}. The rate of calibration (aka adaptation) has been shown to be constant despite the immediate calibration wearing displacement prisms \cite{BR99}. Ziemer et al. \cite{ZBC+13} showed that participants calibrate to a perturbed visual information or walking speed in either real world or IVE using blindfolded walking technique. Additionally, their results indicate that with imagined walking technique, calibration has an effect only when visual information was distorted. In contrary, Nguyen et al. \cite{NZG+11} found distance judgments were unaffected even by a significant scaling of the surrounding environment in IVE in action space. Similar to Bingham and Pagano \cite{BP98}, Bourgeois and Coello \cite{BC12} showed that the calibration occurred in the first few trials when a new shift to visual feedback was introduced in near-field space. Their results indicates that spatial perception can be modified by motor experience with a few interactions with perturbed environment, which cause adaptation to the new visuo-motor constraints in the real world. %Distance judgment have been shown to be affected in some cases and shown to be unaffected in others via visual perturbations. The explanation for these diverse results is still unclear and necessitates future research. Additionally, it is not well known how visual-motor alteration effects distance perception in IVEs with respect to near-field interactions.


Overall, there is a large amount of work that focuses on visuo-motor recalibration through closed-loop interactions in real world \cite{RPA+95,BP98} as well as in VE's \cite{MCT06,KCT13}. To overcome the problem of seeing the world as compressed in VR, some suggested that users' interactions with the environment could potentially change distance estimation in relatively short amount of time \cite{RW05,ANL+12,KHS+14,JSS+11}. In another study, Kelly et al. \cite{KHS+14} showed that only five closed-loop interactions with an IVE significantly improved participants' distance estimates. The result of their study also indicated that the improvements plateaued after a small number of interactions over a fixed range of distances. Much of the work investigating visuo-motor calibration has used open-loop distance judgments with no vision of the target, such as blind walking and blind reaching. Some other techniques such as imagined timed-walking, bean bag throwing, triangulated walking, and verbal report were also used to measure the egocentric distance judgments in IVEs \cite{RVH13}. For instance, Kunz et al. \cite{KWS+09} compared blind-walking and verbal report. They showed there was no significant difference between a low and high quality VE using blind-walking whereas there was a significant difference using verbal report. Similar to Milner and Goodale \cite{MG06}, they suggested that verbal report and action-based responses use different neurological streams and may involve two distinct perceptual processes \cite{NAB+11,PGJ01,FO77}. Overall, all these studies found that verbal judgments were more variable, less accurate, and subject to systematic distortions that were not evident in action responses \cite{PI08,PB98}. For instance, Pagano and Isenhower \cite{PI08} compared verbal report and reaching responses for egocentric distance judgments. They characterized the verbal reports to be more indicative of relative distance perception whereas reaching responses were more indicative of a absolute distance perception. Thus an immediate, action based response that uses physical reach is mainly employed in investigating distance perception via visuo-motor calibration.  

The kinesthetic and proprioceptive cues are a part of visuo-motor system that enhance our awareness of our end effectors (hand and feet) to walk, reach or grab objects even without vision. However, sometimes the link between the kinesthetic and visual information is broken in IVEs. Consequently, performance is affected by this mismatch \cite{so+15}. Hence, many studies have examined users' performance in action space by studying the time and speed of the motion trajectories of the participants' movements to better characterize their behaviors in IVEs \cite{so+15,cp+10,bm+99}. Similarly, in VR applications, such as rehabilitation \cite{DHH+13} and surgical training simulations \cite{S08}, the physical movements play an important role in the user experience and the user interaction with the IVEs. However, in some of these areas, an accurate visual representation of the hand movements in IVEs is crucial and could influence the educational and training outcomes of the simulation. This visual representation of hand movement can be through use of a stylus or an avatar. Altenhoff et al. \cite{ANL+12} studied the effect of visual and tactile feedback on depth perception in IVE via a stylus representation of the hand movements. Ries et al. \cite{RIK+08} and Mohler et al. \cite{MCW+10} showed that even a static self-avatar in the environment improved distance judgment via blind walking. 

Generally, self-avatars are used to give the sense of presence to the users in IVE. Previous work has demonstrated the body ownership illusion in the presence of specific types of synchronous multi-sensory and sensorimotor simulation \cite{SPD+09,SPD+08}. For instance, by having a visual-tactile synchrony, Slater et al. showed that the rubber hand illusion could be replicated in virtual reality \cite{SPD+08}. In their experiment, they hid the real arm and showed a virtual arm to the participants in a large screen display. Then they either provided a synchronous or asynchronous visual and tactile stimulus to the participants. Their results indicate that the visual-tactile synchrony is important in virtual reality application especially for those which require some kind of interaction with the virtual environment. Embodiment could also be induced through first-person viewpoint of the virtual body where there is a visuo-motor synchrony between the real body and virtual representation \cite{BGS13,MS13}.

Despite the importance of self-avatars in IVE, only a few studies have looked at its effect on user's spatial perception. Mohler et al. \cite{MCW+10} explored the effect of articulated self-avatar on absolute egocentric distances in medium space in an IVE. They found participants made more accurate judgments in tracked self-avatar condition as compared to static and no avatar conditions. In another study, Lok et al. \cite{LNW+03} compared object handling in read world, virtual world and a hybrid environment via a self-avatar. They found no effect on the sense of presence between different self-avatar conditions. Williams et al. \cite{WJS+08} also looked at the presence of self-avatar on distance judgments in medium distance in IVE. They found that participants' distance judgment became more accurate when the self-avatar was present for distances smaller than 3m. They observed an significant underestimation for distance greater than 7.5m. Overall, the presence of self-avatar has been shown to have an effect on user's spatial perception. However, to what extent it affects the user's spatial perception in near field in IVE is not well understood.
 
Another body of research has looked at the visual fidelity of avatars in IVE. Volante et al. \cite{VBC+16} investigated the effect of the visual fidelity of the avatar on users' behavioral and emotional responses. They showed that users in visually realistic avatar condition expressed more of the expected emotion towards the avatar as compare to non-photo-realistic conditions. In another study, Lok et al. \cite{LNW+03} compared the real world avatar hand with the virtual and a hybrid representation of it and found no significant effect between the conditions. Regarding virtual humans in IVE, McDonnel et al. \cite{MBB12} found that more realistic avatars can be even more disturbing to the users as compared to less realistic avatars due to the uncanny valley effect. However, there has been no evidence of this phenomenon regarding self-avatars. In another study, Lin and J{\"o}rg \cite{LJ16} showed participants responded to threats in all the conditions from realistic hand to non-anthropomorphic block model. However, the users' responses were strongest in the realistic hand condition and weakest in the wooden block model condition. They concluded that synchronize movements of the avatar hand with the real hand was one of the main factors on inducing the sense of presence and the ownership of the virtual hand. Similarly, Ma and Hommel \cite{MH15} evaluated the hand ownership illusion in situations involving an active operation of the end effector. They found an enhancement on the impression of the hand ownership when coupled with the real hand movements. Overall, the visual fidelity or the rendering style of the avatar and the active operation of the self-avatars have been extensively studied over the last few year in IVE. However, it is less known about the effect of the visual fidelity of the self-avatar on user's spatial perception in near field in IVE.


%The kinesthetic and proprioceptive cues are a part of visuo-motor system that enhance our awareness of our end effectors (hand and feet) to walk, reach or grab objects even without vision. However, sometimes the link between the kinesthetic and visual information is broken in IVEs. Consequently, performance is affected by this mismatch \cite{so+15}. Hence, many studies have examined users' performance in action space by studying the time and speed of the motion trajectories of the participants' movements to better characterize their behaviors in IVEs. For instance, Sanz et al. \cite{so+15} showed that the walking speed decreased along with an increase in the clearance distance when facing virtual obstacles compared to the real ones. In another study, Chihak et al. \cite{cp+10} examined participants' gap crossing or interception performance in the virtual environment by analyzing the speed and time along the approach. They found a systematic difference between children and adults behavior on intercepting a moving gap in virtual blocks. In another study, Buekers et al. \cite{bm+99} examined human locomotion under paced temporal constraints and found that the adaptation to a specific situation was postponed until the final stage of the approach.

%Despite There are relatively few studies on near field distance estimation in IVEs. Previous work by Napieralski et al. \cite{NAB+11} compared near field egocentric distance estimation in an IVE and the RW. In that work, it was seen that distance underestimation took place in both the IVE and RW. The results also showed that distance underestimation increased with distance in both the IVE and the RW. In another study, Singh et al. \cite{SSJ+10} compared closed-loop and open-loop near-field distance estimation in AR. Their results indicated that open-loop blind reaching was significantly underestimated as compared to closed-loop matching task. Despite the importance of near field distance estimation, there are very few studies in this area in VR. Rolland et al. \cite{RBG+95}, showed overestimation in near field distance judgments in AR using a forced-choice task. Taken together, these studies have shown that near field AR and VR introduce substantial distortions in distance judgments as compared to the real world \cite{SSJ+10,ANL+12,NAB+11}.


%As discussed in the previous paragraphs, the effect of closed-loop interactions with an environment, in terms of distance estimation, is well known in the medium field for both VR and RW. In those cases, distance judgments significantly improved after users interact with the environment \cite{RW05,ANL+12,KHS+14}. As previously discussed, there is very little work comparing open and closed-loop near field distance judgments in either AR or VR environments. Also, the impact of visual and proprioceptive information during closed-loop visuo-motor calibration in the IVE has not been well examined.


%Recent research on the effects of visuo-motor calibration in an IVE has studied the different forms of sensory feedback. For instance, Altenhoff et al. \cite{ANL+12} investigated whether visual and haptic feedback could potentially improve depth judgments. In that work, participants' distance estimates were measured before and after their interaction with near field targets using both visual and haptic feedback. The result of their study showed that the users' performance significantly improved after the visuo-motor calibration interactions. Mohler et al. \cite{MCT06} also indicated that users' performance when walking on a treadmill in the real world similarly matched their performance in an IVE while vision was coupled with action. Likewise, Bingham and Romack \cite{BR99} studied real world calibration in users' physical reaches with displacement prisms over the course of three-days. They pointed out that calibration improved daily with participants interacting with the real world quite naturally by the third day. Another aspect of this research is to study the impact of haptic feedback on hand reaching motion. Haptic feedback provides a sense of limb position and movement as well as an apprehension of object properties such as hardness, extent, orientation, weight and inertia \cite{PT92,pt98}. Haptic feedback and its role on precise perception has drawn more attention to it in VR \cite{bb+96}. 

